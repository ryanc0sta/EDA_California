{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ//irGbIVIOde2WwbVgv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanc0sta/EDA_California/blob/main/EDA_California.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análise Exploratória de Dados completa com representações gráficas do Dataset [California Housing Prices](https://raw.githubusercontent.com/TailUFPB/processo2fase/refs/heads/master/2025/data/california.csv)."
      ],
      "metadata": {
        "id": "OWpCy8R_sfpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### IMPORTAÇÕES E CONFIGURAÇÕES\n",
        "\n",
        "\n",
        "### Obs: utilizei ia principalmente na organização e no visual da criação de gráficos, parte que\n",
        "### infelizmente ainda não dominei por completo.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, Markdown\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"Set2\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.labelsize'] = 11\n",
        "plt.rcParams['axes.titlesize'] = 12\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)"
      ],
      "metadata": {
        "id": "kHmln8clsw8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/TailUFPB/processo2fase/refs/heads/master/2025/data/california.csv')\n",
        "df\n",
        "\n",
        "### VISÃO GERAL DO DATASET\n",
        "\n",
        "def visao_geral(df):\n",
        "    print(\"\\n\" + \"-\"*80)\n",
        "    print(\"INFORMAÇÕES GERAIS DO DATASET\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    ### Informações básicas\n",
        "    print(f\"\\nDimensões: {df.shape[0]} linhas × {df.shape[1]} colunas\")\n",
        "    print(f\"Memória utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    print(\"\\nTipos de Dados:\")\n",
        "    print(df.dtypes.value_counts())\n",
        "\n",
        "    print(\"\\nInformações:\")\n",
        "    df.info()\n",
        "\n",
        "teste = visao_geral(df)\n",
        "teste"
      ],
      "metadata": {
        "id": "7bpKvDMqs0mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### CÁLCULO ESTATÍSTICO DETALHADO (visualização com dataframe)\n",
        "\n",
        "def calcular_estatisticas_detalhadas(df):\n",
        "    resumo = {}\n",
        "    total_registros = len(df)\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_data = df[col]\n",
        "        is_numeric = pd.api.types.is_numeric_dtype(col_data)\n",
        "        is_categorical = pd.api.types.is_categorical_dtype(col_data)\n",
        "\n",
        "        ### Aqui faço o pré-cálculo de valores que se repetirão para otimizar o desempenho\n",
        "        valores_faltantes = col_data.isnull().sum()\n",
        "        perc_faltantes = (valores_faltantes / total_registros * 100)\n",
        "\n",
        "        ### Inicializar stats base (comuns a todos os tipos)\n",
        "        stats = {\n",
        "            'Tipo': str(col_data.dtype),\n",
        "            'Total Registros': total_registros,\n",
        "            'Valores Únicos': col_data.nunique(),\n",
        "            'Valores Faltantes': valores_faltantes,\n",
        "            '% Faltantes': f\"{perc_faltantes:.2f}%\",\n",
        "        }\n",
        "\n",
        "        ### Processando os valores numéricos\n",
        "        if is_numeric:\n",
        "            zeros = (col_data == 0).sum()\n",
        "            media = col_data.mean()\n",
        "            mediana = col_data.median()\n",
        "            desvio = col_data.std()\n",
        "            minimo = col_data.min()\n",
        "            maximo = col_data.max()\n",
        "\n",
        "            ### Quartis\n",
        "            q1 = col_data.quantile(0.25)\n",
        "            q3 = col_data.quantile(0.75)\n",
        "            iqr = q3 - q1\n",
        "\n",
        "            ### Outliers\n",
        "            limite_inf = q1 - 1.5 * iqr\n",
        "            limite_sup = q3 + 1.5 * iqr\n",
        "            outliers = ((col_data < limite_inf) | (col_data > limite_sup)).sum()\n",
        "\n",
        "            ### Moda\n",
        "            moda_values = col_data.mode()\n",
        "            moda = moda_values[0] if len(moda_values) > 0 else '-'\n",
        "\n",
        "            ### Assimetria e Curtose\n",
        "            assimetria = col_data.skew()\n",
        "            curtose = col_data.kurtosis()\n",
        "\n",
        "            ### CV\n",
        "            cv = (desvio / media * 100) if media != 0 else None\n",
        "\n",
        "            ### Adicionando ao dicionário\n",
        "            stats.update({\n",
        "                'Zeros': zeros,\n",
        "                '% Zeros': f\"{(zeros / total_registros * 100):.2f}%\",\n",
        "                'Média': f\"{media:.2f}\",\n",
        "                'Mediana': f\"{mediana:.2f}\",\n",
        "                'Moda': moda,\n",
        "                'Desvio Padrão': f\"{desvio:.2f}\",\n",
        "                'CV (%)': f\"{cv:.2f}%\" if cv is not None else '-',\n",
        "                'Mínimo': f\"{minimo:.2f}\",\n",
        "                'Q1 (25%)': f\"{q1:.2f}\",\n",
        "                'Q3 (75%)': f\"{q3:.2f}\",\n",
        "                'Máximo': f\"{maximo:.2f}\",\n",
        "                'IQR': f\"{iqr:.2f}\",\n",
        "                'Outliers': outliers,\n",
        "                '% Outliers': f\"{(outliers / total_registros * 100):.2f}%\",\n",
        "                'Assimetria': f\"{assimetria:.2f}\",\n",
        "                'Curtose': f\"{curtose:.2f}\",\n",
        "            })\n",
        "\n",
        "        ### Agora faendo o processamento de cada categoria\n",
        "        elif is_categorical:\n",
        "            value_counts = col_data.value_counts()\n",
        "\n",
        "            stats.update({\n",
        "                'Zeros': '-',\n",
        "                '% Zeros': '-',\n",
        "                'Média': '-',\n",
        "                'Mediana': '-',\n",
        "                'Moda': value_counts.index[0] if len(value_counts) > 0 else '-',\n",
        "                'Desvio Padrão': '-',\n",
        "                'CV (%)': '-',\n",
        "                'Mínimo': '-',\n",
        "                'Q1 (25%)': '-',\n",
        "                'Q3 (75%)': '-',\n",
        "                'Máximo': '-',\n",
        "                'IQR': '-',\n",
        "                'Outliers': '-',\n",
        "                '% Outliers': '-',\n",
        "                'Assimetria': '-',\n",
        "                'Curtose': '-',\n",
        "                'Categorias': ', '.join(map(str, col_data.cat.categories.tolist())),\n",
        "                'Mais Frequente': value_counts.index[0] if len(value_counts) > 0 else '-',\n",
        "                'Freq. Mais Comum': value_counts.iloc[0] if len(value_counts) > 0 else '-',\n",
        "                '% Mais Comum': f\"{(value_counts.iloc[0] / total_registros * 100):.2f}%\" if len(value_counts) > 0 else '-',\n",
        "            })\n",
        "\n",
        "        ### outros tipos\n",
        "        else:\n",
        "            moda_values = col_data.mode()\n",
        "\n",
        "            stats.update({\n",
        "                'Zeros': '-',\n",
        "                '% Zeros': '-',\n",
        "                'Média': '-',\n",
        "                'Mediana': '-',\n",
        "                'Moda': moda_values[0] if len(moda_values) > 0 else '-',\n",
        "                'Desvio Padrão': '-',\n",
        "                'CV (%)': '-',\n",
        "                'Mínimo': str(col_data.min()) if len(col_data) > 0 else '-',\n",
        "                'Q1 (25%)': '-',\n",
        "                'Q3 (75%)': '-',\n",
        "                'Máximo': str(col_data.max()) if len(col_data) > 0 else '-',\n",
        "                'IQR': '-',\n",
        "                'Outliers': '-',\n",
        "                '% Outliers': '-',\n",
        "                'Assimetria': '-',\n",
        "                'Curtose': '-',\n",
        "            })\n",
        "\n",
        "        resumo[col] = pd.Series(stats)\n",
        "\n",
        "    return pd.DataFrame(resumo).T\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"ESTATÍSTICAS DESCRITIVAS COMPLETAS\")\n",
        "print(\"\\n\")\n",
        "\n",
        "estatisticas = calcular_estatisticas_detalhadas(df)\n",
        "display(estatisticas)\n",
        "\n",
        "### Salvar o resultado como csv\n",
        "estatisticas.to_csv('estatisticas_descritivas.csv')\n",
        "print(\"\\nEstatísticas salvas como 'estatisticas_descritivas.csv'\")"
      ],
      "metadata": {
        "id": "dxPVwAm6s3Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA e gráficos\n"
      ],
      "metadata": {
        "id": "6raOnVCTs_6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### EDA E GRÁFICOS\n",
        "\n",
        "df_numeric = df.select_dtypes(include=[np.number])\n",
        "\n",
        "### Observação: As colunas households, median_income, median_house_value e ocean_proximity não estão sendo identificadas como numéricos e precisam ser tratadas.\n",
        "\n",
        "def limpar_e_converter_dados(df):\n",
        "    df_limpo = df.copy()\n",
        "\n",
        "    # Colunas que DEVEM ser numéricas\n",
        "    colunas_numericas = ['longitude', 'latitude', 'housing_median_age','total_rooms', 'total_bedrooms', 'population','households', 'median_income', 'median_house_value']\n",
        "\n",
        "    for col in colunas_numericas:\n",
        "        if col in df_limpo.columns:\n",
        "            ### Aqui eu converto para str primeiro\n",
        "            df_limpo[col] = df_limpo[col].astype(str)\n",
        "\n",
        "            ### Removendo espaços em branco\n",
        "            df_limpo[col] = df_limpo[col].str.strip()\n",
        "\n",
        "            ### Aqui eu removo as vírgulas\n",
        "            df_limpo[col] = df_limpo[col].str.replace(',', '', regex=False)\n",
        "\n",
        "            ### Removendo cifrões e outros símbolos monetários\n",
        "            df_limpo[col] = df_limpo[col].str.replace('$', '', regex=False)\n",
        "            df_limpo[col] = df_limpo[col].str.replace('R$', '', regex=False)\n",
        "\n",
        "            ### Aqui eu removo os espaços extras que podem ter ficado\n",
        "            df_limpo[col] = df_limpo[col].str.replace(' ', '', regex=False)\n",
        "\n",
        "            ### Aqui eu converto para numérico (erros viram NaN)\n",
        "            df_limpo[col] = pd.to_numeric(df_limpo[col], errors='coerce')\n",
        "\n",
        "            print(f\"{col}: convertido para {df_limpo[col].dtype}\")\n",
        "\n",
        "    ### ocean_proximity pode ser categorica\n",
        "    if 'ocean_proximity' in df_limpo.columns:\n",
        "        df_limpo['ocean_proximity'] = df_limpo['ocean_proximity'].astype(str).str.strip()\n",
        "        df_limpo['ocean_proximity'] = df_limpo['ocean_proximity'].astype('category')\n",
        "        print(f\"ocean_proximity: convertido para categoria (não é numérico!)\")\n",
        "\n",
        "    return df_limpo\n",
        "\n",
        "df_limpo = limpar_e_converter_dados(df)\n",
        "\n",
        "### Verificar tipos\n",
        "print(\"\\n\")\n",
        "print(\"TIPOS DE DADOS APÓS ESSE TRATAMENTO:\")\n",
        "print(\"\\n\")\n",
        "print(df_limpo.dtypes)\n",
        "print(\"\\n\")\n",
        "\n",
        "### Selecionar apenas colunas numéricas\n",
        "df_numeric = df_limpo.select_dtypes(include=[np.number])\n",
        "print(\"\\n\")\n",
        "print(f\"COLUNAS NUMÉRICAS IDENTIFICADAS: {len(df_numeric.columns)}\")\n",
        "print(\"\\n\")\n",
        "print(df_numeric.columns.tolist())\n",
        "print(\"\\n\")\n",
        "\n",
        "### Calcular estatísticas novamente\n",
        "estatisticas = calcular_estatisticas_detalhadas(df_limpo)\n",
        "display(estatisticas)"
      ],
      "metadata": {
        "id": "il1wVxgDtCNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### GRÁFICO PARA MEDIDAS DE LOCALIZAÇÃO\n",
        "\n",
        "### Decidi usar boxplots pois permitem comparação visual direta entre diferentes grupos e,\n",
        "### por serem compactos, permitem visualizar múltiplas variáveis lado a lado para análise comparativa\n",
        "\n",
        "def boxplots_por_localizacao(df_limpo):\n",
        "    variaveis = ['median_house_value', 'median_income', 'housing_median_age', 'population']\n",
        "    cores = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
        "\n",
        "    ### Extraindo um insight importante de cada gráfico:\n",
        "    insights = {\n",
        "        'median_house_value': \"\"\"\n",
        "INSIGHTS: Median House Value\n",
        "- Bairros mais próximos do oceano (<1H OCEAN, NEAR OCEAN, NEAR BAY, ISLAND) têm valores medianos de imóveis claramente mais altos que INLAND.\n",
        "- A dispersão é maior nas regiões costeiras, indicando maior heterogeneidade de preços e presença de imóveis muito caros.\n",
        "\"\"\",\n",
        "        'median_income': \"\"\"\n",
        "INSIGHTS: Median Income\n",
        "- A renda mediana segue o padrão do valor dos imóveis: categorias mais próximas do oceano concentram rendas mais altas.\n",
        "- INLAND apresenta mediana e média de renda menores do que <1H OCEAN e NEAR OCEAN, sugerindo que regiões costeiras concentram moradores com maior poder aquisitivo.\n",
        "\"\"\",\n",
        "        'housing_median_age': \"\"\"\n",
        "INSIGHTS: Housing Median Age\n",
        "- As diferenças entre categorias de ocean_proximity são menos extremas do que em renda e valor do imóvel.\n",
        "- Algumas áreas costeiras apresentam bairros um pouco mais antigos, o que pode indicar cidades mais consolidadas historicamente.\n",
        "- Regiões INLAND parecem ter mistura maior de bairros novos e antigos, refletindo expansão urbana mais recente em algumas áreas.\n",
        "\"\"\",\n",
        "        'population': \"\"\"\n",
        "INSIGHTS: Population\n",
        "- Há grande variabilidade de população em todas as categorias.\n",
        "- Existem quarteirões muito densos tanto em regiões costeiras quanto em partes INLAND (grandes cidades interioranas).\n",
        "- ISLAND tende a ter população mais baixa e menos dispersão, sugerindo poucos registros e bairros menos densos.\n",
        "- No geral, a proximidade ao oceano não explica tanto a população quanto explica renda e valor do imóvel; a densidade populacional está mais espalhada entre as categorias.\n",
        "\"\"\"\n",
        "    }\n",
        "\n",
        "    for var in variaveis:\n",
        "        if var in df_limpo.columns and 'ocean_proximity' in df_limpo.columns:\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "            ### Criando o bloxplot\n",
        "            sns.boxplot(\n",
        "                data=df_limpo,\n",
        "                x='ocean_proximity',\n",
        "                y=var,\n",
        "                ax=ax,\n",
        "                palette=cores,\n",
        "                width=0.6,\n",
        "                linewidth=2\n",
        "            )\n",
        "\n",
        "            medias = df_limpo.groupby('ocean_proximity')[var].mean()\n",
        "            posicoes = range(len(medias))\n",
        "            ax.scatter(\n",
        "                posicoes, medias, color='red', s=100,\n",
        "                zorder=10, label='Média', marker='D'\n",
        "            )\n",
        "\n",
        "            ### Criei uma linha que representa a mediana\n",
        "            mediana_geral = df_limpo[var].median()\n",
        "            ax.axhline(\n",
        "                mediana_geral, color='darkred', linestyle='--', linewidth=2, alpha=0.5,\n",
        "                label=f'Mediana Geral: {mediana_geral:,.0f}'\n",
        "            )\n",
        "\n",
        "            ### Aqui eu fiz a formatação\n",
        "            ax.set_title(\n",
        "                f'{var.replace(\"_\", \" \").title()}',\n",
        "                fontsize=14, weight='bold', pad=15\n",
        "            )\n",
        "            ax.set_xlabel('Proximidade do Oceano', fontsize=11, weight='bold')\n",
        "            ax.set_ylabel(var.replace(\"_\", \" \").title(), fontsize=11, weight='bold')\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "            ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "            ax.legend(loc='upper right')\n",
        "\n",
        "            plt.tight_layout(pad=3.0)\n",
        "            fig.subplots_adjust(top=0.9, bottom=0.15)\n",
        "\n",
        "            plt.savefig(f'boxplot_localizacao_{var}.png', dpi=300, bbox_inches='tight')\n",
        "            print(f'Gráfico salvo como: boxplot_localizacao_{var}.png')\n",
        "            plt.show()\n",
        "            plt.close(fig)\n",
        "\n",
        "            ### Printando os insights\n",
        "            if var in insights:\n",
        "                print(\"\\n\")\n",
        "                print(insights[var].strip())\n",
        "                print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
        "\n",
        "boxplots_por_localizacao(df_limpo)"
      ],
      "metadata": {
        "id": "c2S6RZbctFox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### GRÁFICO PARA MEDIDAS DE DISPERSÃO\n",
        "\n",
        "### Decidi usar um gráfico de barras simples para representar as medidas de dispersão já que o comprimento da barra\n",
        "### pode medir a magnitude da dispersão de forma muito prática visualmente, não precisando de um conhecimento estatístico\n",
        "### muito avançado.\n",
        "\n",
        "def grafico_cv_por_grupo(df_limpo):\n",
        "\n",
        "    ### Irei trabalhar com o coeficiente de variação. Escolhi porque ele permite comparar\n",
        "    ### a dispersão relativa entre variáveis com escalas completamente diferentes.\n",
        "\n",
        "    variaveis = ['median_house_value', 'median_income', 'housing_median_age', 'population']\n",
        "\n",
        "    ### Comentários gerais pra cada gráfico\n",
        "    insights_cv = {\n",
        "        'median_house_value': \"\"\"\n",
        "INSIGHTS: Dispersão (Median House Value)\n",
        "- O coeficiente de variação revela o quão heterogêneos são os preços dos imóveis dentro de cada grupo de proximidade ao oceano.\n",
        "- Grupos com CV mais alto indicam mercados imobiliários mais desiguais, onde coexistem imóveis muito baratos e muito caros.\n",
        "\"\"\",\n",
        "        'median_income': \"\"\"\n",
        "INSIGHTS: Dispersão (Median Income)\n",
        "- O CV da renda mostra o quanto a renda da população varia dentro de cada grupo.\n",
        "- Grupos com CV mais alto sugerem maior desigualdade de renda entre os moradores daquela região.\n",
        "\"\"\",\n",
        "        'housing_median_age': \"\"\"\n",
        "INSIGHTS: Dispersão (Housing Median Age)\n",
        "- O CV da idade mediana das casas indica se os bairros daquele grupo são mais homogêneos (casas de épocas parecidas)\n",
        "  ou se há mistura de construções antigas e recentes.\n",
        "\"\"\",\n",
        "        'population': \"\"\"\n",
        "INSIGHTS: Dispersão (Population)\n",
        "- O CV da população mostra quanta variação existe no tamanho dos quarteirões dentro de cada grupo de proximidade ao oceano.\n",
        "- Grupos com CV mais alto reúnem desde quarteirões pouco povoados até áreas extremamente densas.\n",
        "\"\"\"}\n",
        "\n",
        "    for i, var in enumerate(variaveis):\n",
        "        if var in df_limpo.columns and 'ocean_proximity' in df_limpo.columns:\n",
        "\n",
        "            ### Criar figura individual para cada variável\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "            ### Calculando o cv\n",
        "            cv_por_grupo = (\n",
        "                df_limpo\n",
        "                .groupby('ocean_proximity')[var]\n",
        "                .apply(lambda x: (x.std() / x.mean() * 100) if x.mean() != 0 else 0)\n",
        "                .sort_values(ascending=False)\n",
        "            )\n",
        "\n",
        "            ### Organizando o gráfico de barras\n",
        "            bars = ax.barh(\n",
        "                range(len(cv_por_grupo)),\n",
        "                cv_por_grupo.values,\n",
        "                color='blue',\n",
        "                alpha=0.8,\n",
        "                edgecolor='black',\n",
        "                linewidth=1.5\n",
        "            )\n",
        "\n",
        "            ### Adicionar valores nas barras\n",
        "            for j, (bar, val) in enumerate(zip(bars, cv_por_grupo.values)):\n",
        "                ax.text(\n",
        "                    val + 1,\n",
        "                    bar.get_y() + bar.get_height()/2,\n",
        "                    f'{val:.1f}%',\n",
        "                    va='center',\n",
        "                    fontsize=10,\n",
        "                    weight='bold'\n",
        "                )\n",
        "\n",
        "            ### Formatação dos eixos e título\n",
        "            ax.set_yticks(range(len(cv_por_grupo)))\n",
        "            ax.set_yticklabels(cv_por_grupo.index, fontsize=10)\n",
        "            ax.set_xlabel('Coeficiente de Variação (%)', fontsize=11, weight='bold')\n",
        "            ax.set_title(\n",
        "                f'Dispersão Relativa - {var.replace(\"_\", \" \").title()}',\n",
        "                fontsize=14,\n",
        "                weight='bold',\n",
        "                pad=15\n",
        "            )\n",
        "            ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
        "\n",
        "            ### CV médio\n",
        "            cv_medio = cv_por_grupo.mean()\n",
        "            ax.axvline(\n",
        "                cv_medio,\n",
        "                color='darkred',\n",
        "                linestyle='--',\n",
        "                linewidth=2,\n",
        "                alpha=0.7,\n",
        "                label=f'CV Médio: {cv_medio:.1f}%'\n",
        "            )\n",
        "            ax.legend()\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'cv_dispersao_{var}.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "            ### Salvando os gráficos:\n",
        "            print(f'Gráfico salvo: cv_dispersao_{var}.png')\n",
        "            plt.show()\n",
        "            plt.close(fig)\n",
        "\n",
        "            ### Comentário (insight) após cada gráfico\n",
        "            cat_max = cv_por_grupo.idxmax()\n",
        "            val_max = cv_por_grupo.max()\n",
        "            cat_min = cv_por_grupo.idxmin()\n",
        "            val_min = cv_por_grupo.min()\n",
        "\n",
        "            print(\"\\n\")\n",
        "            if var in insights_cv:\n",
        "                print(insights_cv[var].strip())\n",
        "            print(f\"Maior CV em: {cat_max} ({val_max:.1f}%)\")\n",
        "            print(f\"Menor CV em: {cat_min} ({val_min:.1f}%)\")\n",
        "            print(\"\\n\"+\"-\"*60+\"\\n\")\n",
        "\n",
        "\n",
        "grafico_cv_por_grupo(df_limpo)"
      ],
      "metadata": {
        "id": "2WURVBa0tIqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### GRÁFICO PARA VALORES ÚNICOS (CARDINALIDADE)\n",
        "\n",
        "### Escolhi gráfico de barras horizontal porque facilita a leitura dos nomes das colunas (sem rotação),\n",
        "### permite comparação imediata através do comprimento das barras e usa cores para classificar automaticamente\n",
        "### as variáveis (categóricas em vermelho, média em laranja, alta cardinalidade em azul). Essa visualização\n",
        "### é essencial para identificar a diversidade dos dados.\n",
        "\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "def grafico_valores_unicos_horizontal(df_limpo):\n",
        "    valores_unicos = df_limpo.nunique().sort_values(ascending=True)\n",
        "    total_registros = len(df_limpo)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    ### Escolhendo as cores.\n",
        "    cores = []\n",
        "    for v in valores_unicos.values:\n",
        "        if v < 10:\n",
        "            cores.append('#E74C3C')  ### Vermelho - Categórica\n",
        "        elif v < 1000:\n",
        "            cores.append('#F39C12')  ### Laranja - Média\n",
        "        else:\n",
        "            cores.append('#3498DB')  ### Azul - Alta\n",
        "\n",
        "    bars = ax.barh(\n",
        "        range(len(valores_unicos)),\n",
        "        valores_unicos.values,\n",
        "        color=cores,\n",
        "        alpha=0.8,\n",
        "        edgecolor='black',\n",
        "        linewidth=1.5\n",
        "    )\n",
        "\n",
        "    for i, (bar, val) in enumerate(zip(bars, valores_unicos.values)):\n",
        "        width = bar.get_width()\n",
        "        ax.text(\n",
        "            width + total_registros*0.02,\n",
        "            bar.get_y() + bar.get_height()/2,\n",
        "            f'{val:,}',\n",
        "            va='center',\n",
        "            fontsize=10,\n",
        "            weight='bold'\n",
        "        )\n",
        "\n",
        "    ### Formatação.\n",
        "    ax.set_yticks(range(len(valores_unicos)))\n",
        "    ax.set_yticklabels(valores_unicos.index, fontsize=11)\n",
        "    ax.set_xlabel('Quantidade de Valores Únicos', fontsize=12, weight='bold')\n",
        "    ax.set_title(\n",
        "        'Cardinalidade das Variáveis (Valores Únicos)',\n",
        "        fontsize=14,\n",
        "        weight='bold',\n",
        "        pad=15\n",
        "    )\n",
        "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
        "\n",
        "    ### Linha de referência: total de registros\n",
        "    ax.axvline(\n",
        "        total_registros,\n",
        "        color='darkred',\n",
        "        linestyle='--',\n",
        "        linewidth=2,\n",
        "        alpha=0.5,\n",
        "        label=f'Total: {total_registros:,}'\n",
        "    )\n",
        "\n",
        "    ### Legenda do gráfico:\n",
        "    legend_elements = [\n",
        "        Patch(facecolor='#E74C3C', label='Categórica (< 10)'),\n",
        "        Patch(facecolor='#F39C12', label='Média (10-1000)'),\n",
        "        Patch(facecolor='#3498DB', label='Alta (> 1000)'),\n",
        "        Patch(facecolor='none', edgecolor='darkred', linestyle='--', label='Total de Registros')\n",
        "    ]\n",
        "    ax.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('cardinalidade_horizontal.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    ### Salvando o gráfico\n",
        "    print('Gráfico salvo: cardinalidade_horizontal.png')\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "    # ---------------- INSIGHTS APÓS O GRÁFICO ----------------\n",
        "    col_max = valores_unicos.idxmax()\n",
        "    val_max = valores_unicos.max()\n",
        "    col_min = valores_unicos.idxmin()\n",
        "    val_min = valores_unicos.min()\n",
        "\n",
        "    qtd_baixa = (valores_unicos < 10).sum()\n",
        "    qtd_media = ((valores_unicos >= 10) & (valores_unicos < 1000)).sum()\n",
        "    qtd_alta = (valores_unicos >= 1000).sum()\n",
        "\n",
        "    print(\"\"\"\n",
        "INSIGHTS:\n",
        "- O gráfico mostra como cada coluna varia em termos de quantidade de valores distintos (diversidade de informação).\n",
        "- Variáveis com baixa cardinalidade (< 10) tendem a ser boas candidatas a variáveis categóricas.\n",
        "- Variáveis com cardinalidade muito alta podem exigir tratamentos específicos (por exemplo, agrupar categorias raras).\n",
        "\"\"\".strip())\n",
        "    print(f\"\\nColuna com MAIOR cardinalidade: {col_max} ({val_max:,} valores únicos)\")\n",
        "    print(f\"Coluna com MENOR cardinalidade: {col_min} ({val_min:,} valores únicos)\")\n",
        "    print(f\"\\nQuantidade de variáveis com baixa cardinalidade (< 10): {qtd_baixa}\")\n",
        "    print(f\"Quantidade de variáveis com cardinalidade média (10–1000): {qtd_media}\")\n",
        "    print(f\"Quantidade de variáveis com alta cardinalidade (> 1000): {qtd_alta}\")\n",
        "    print(\"\\n\"+\"-\"*60+\"\\n\")\n",
        "\n",
        "grafico_valores_unicos_horizontal(df_limpo)"
      ],
      "metadata": {
        "id": "GhNzryJUtLaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### GRÁFICO GEOGRÁFICO: Mapa de Preços e Densidade Populacional\n",
        "### Este gráfico é essencial porque explora a dimensão espacial dos dados, revelando\n",
        "### padrões geográficos que nao aparecem em estatísticas agregadas. O tamanho dos pontos\n",
        "### representa população e a cor representa preço, permitindo identificar visualmente\n",
        "### áreas metropolitanas caras (São Francisco, Los Angeles) e regiões mais baratas (interior).\n",
        "\n",
        "def mapa_geografico_precos(df_limpo):\n",
        "\n",
        "    ### MAPA 1: PREÇO MEDIANO POR LOCALIZAÇÃO\n",
        "\n",
        "    fig1, ax1 = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "    scatter1 = ax1.scatter(\n",
        "        df_limpo['longitude'],\n",
        "        df_limpo['latitude'],\n",
        "        c=df_limpo['median_house_value'],\n",
        "        s=df_limpo['population'] / 100,\n",
        "        cmap='YlOrRd',\n",
        "        alpha=0.4,\n",
        "        edgecolors='k',\n",
        "        linewidth=0.1\n",
        "    )\n",
        "\n",
        "    cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
        "    cbar1.set_label('Valor Mediano da Casa', fontsize=11, weight='bold')\n",
        "\n",
        "    ### Formatação\n",
        "    ax1.set_xlabel('Longitude', fontsize=12, weight='bold')\n",
        "    ax1.set_ylabel('Latitude', fontsize=12, weight='bold')\n",
        "    ax1.set_title('Distribuição Geográfica dos Preços de Imóveis\\n(Tamanho = População)',\n",
        "                  fontsize=14, weight='bold', pad=15)\n",
        "    ax1.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('mapa_precos_california.png', dpi=300, bbox_inches='tight')\n",
        "    print('Gráfico salvo como: mapa_precos_california.png')\n",
        "    plt.show()\n",
        "    plt.close(fig1)\n",
        "\n",
        "    ### INSIGHTS DO MAPA DE PREÇOS\n",
        "    print(\"\"\"\n",
        "INSIGHTS:\n",
        "- A análise espacial revela que a localização é o fator dominante no preço dos imóveis da Califórnia.\n",
        "- Observa-se um gradiente claro de valorização do litoral para o interior: regiões costeiras\n",
        "  apresentam, em geral, casas mais caras que o interior.\n",
        "- Três grandes clusters metropolitanos (Bay Area, Los Angeles e San Diego) concentram os maiores preços,\n",
        "  reforçando o papel de grandes centros urbanos e da proximidade ao oceano na valorização imobiliária.\n",
        "- Nota-se também heterogeneidade local: mesmo dentro de uma mesma região, distritos vizinhos podem\n",
        "  apresentar variações de cerca de 50% no preço, mostrando que microlocalizações importam muito.\n",
        "\"\"\".strip())\n",
        "    print(\"\\n\"+\"-\"*60 +\"\\n\")\n",
        "\n",
        "\n",
        "    ### MAPA 2: RENDA MEDIANA POR LOCALIZAÇÃO\n",
        "\n",
        "    fig2, ax2 = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "    scatter2 = ax2.scatter(\n",
        "        df_limpo['longitude'],\n",
        "        df_limpo['latitude'],\n",
        "        c=df_limpo['median_income'],\n",
        "        s=df_limpo['population'] / 100,\n",
        "        cmap='viridis',\n",
        "        alpha=0.4,\n",
        "        edgecolors='k',\n",
        "        linewidth=0.1\n",
        "    )\n",
        "\n",
        "    cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
        "    cbar2.set_label('Renda Mediana (×$10,000)', fontsize=11, weight='bold')\n",
        "\n",
        "    ### Formatação\n",
        "    ax2.set_xlabel('Longitude', fontsize=12, weight='bold')\n",
        "    ax2.set_ylabel('Latitude', fontsize=12, weight='bold')\n",
        "    ax2.set_title('Distribuição Geográfica da Renda\\n(Tamanho = População)',\n",
        "                  fontsize=14, weight='bold', pad=15)\n",
        "    ax2.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('mapa_renda_california.png', dpi=300, bbox_inches='tight')\n",
        "    print('Gráfico salvo como: mapa_renda_california.png')\n",
        "    plt.show()\n",
        "    plt.close(fig2)\n",
        "\n",
        "    ### INSIGHTS DO MAPA DE RENDA\n",
        "    print(\"\"\"\n",
        "INSIGHTS:\n",
        "- Os clusters de maior renda coincidem fortemente com as mesmas regiões de preços elevados\n",
        "  (Bay Area, Los Angeles e San Diego), indicando que renda e preço têm correlação não só numérica,\n",
        "  mas também geográfica.\n",
        "- A proximidade do oceano é crítica: áreas costeiras concentram não apenas imóveis mais caros,\n",
        "  mas também moradores com maior poder aquisitivo.\n",
        "- Comparando os dois mapas (preço e renda), fica evidente que casas costeiras podem valer de 2 a 3 vezes\n",
        "  mais do que imóveis semelhantes no interior, reforçando o papel central da localização na dinâmica do mercado.\n",
        "\"\"\".strip())\n",
        "    print(\"\\n\"+\"-\"*60+\"\\n\")\n",
        "\n",
        "mapa_geografico_precos(df_limpo)"
      ],
      "metadata": {
        "id": "P7i3DybNtSPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering e Dados Categóricos"
      ],
      "metadata": {
        "id": "TTaZF54stU0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_fe = df_limpo.copy()\n",
        "\n",
        "### A combinação de variáveis de “totais” em razões/densidades é importante porque os\n",
        "### totais brutos (total_rooms, total_bedrooms, population, households) são altamente correlacionados\n",
        "### entre si e refletem mais o tamanho do distrito do que suas características estruturais.\n",
        "### Ao transformá‑los em métricas relativas, como rooms_per_household, population_per_household e bedrooms_per_room, passamos a medir intensidade\n",
        "### e composição (tamanho médio das casas, lotação média por domicílio, proporção de quartos), que são muito mais comparáveis entre regiões de\n",
        "### tamanhos diferentes.\n",
        "\n",
        "num_cols_needed = ['total_rooms', 'total_bedrooms', 'population', 'households']\n",
        "if all(col in df_fe.columns for col in num_cols_needed):\n",
        "    ### Evitando a divisão por 0\n",
        "    for col in ['households', 'total_rooms']:\n",
        "        df_fe.loc[df_fe[col] == 0, col] = np.nan\n",
        "\n",
        "    ### Features novas criadas:\n",
        "    df_fe['rooms_per_household'] = df_fe['total_rooms'] / df_fe['households']\n",
        "    df_fe['population_per_household'] = df_fe['population'] / df_fe['households']\n",
        "    df_fe['bedrooms_per_room'] = df_fe['total_bedrooms'] / df_fe['total_rooms']\n",
        "\n",
        "    ### Removendo as colunas originais\n",
        "    cols_to_drop = ['total_rooms', 'total_bedrooms', 'population', 'households']\n",
        "    df_fe.drop(columns=[c for c in cols_to_drop if c in df_fe.columns], inplace=True)\n",
        "\n",
        "### Transformar latitude e longitude em um “cluster de região” (por exemplo, via K‑Means) serve para capturar a informação geográfica de forma mais simples e útil ao modelo.\n",
        "### Em vez de lidar com duas coordenadas contínuas e muito granulares, o modelo passa a enxergar poucas regiões discretas que representam áreas com\n",
        "### comportamento imobiliário semelhante (ex.: grandes regiões metropolitanas, interior, litoral).\n",
        "### Isso reduz a dimensionalidade, diminui o ruído de microdiferenças de localização (quarteirão a quarteirão) e facilita a generalização:\n",
        "### o foco deixa de ser a coordenada exata e passa a ser a macro‑região econômica em que o imóvel está inserido, que é o que realmente influencia preço,\n",
        "### renda e outras variáveis de interesse.\n",
        "\n",
        "if {'latitude', 'longitude'}.issubset(df_fe.columns):\n",
        "    coords = df_fe[['latitude', 'longitude']]\n",
        "\n",
        "    ### Aqui eu uso KMeans para agrupar a Califórnia em K regiões\n",
        "    kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "    df_fe['region_cluster'] = kmeans.fit_predict(coords)\n",
        "\n",
        "    ### Removendo as colunas originais\n",
        "    df_fe.drop(columns=['latitude', 'longitude'], inplace=True)\n",
        "\n",
        "\n",
        "df_fe"
      ],
      "metadata": {
        "id": "1SAWLAy6tXsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Uma forma correta de fazer isso é usar codificação one‑hot, criando colunas binárias 0/1 para indicar a presença de cada categoria.\n",
        "### No caso da questão, primeiro simplifiquei a variável ocean_proximity em dois grupos (INLAND e COASTAL) e, em seguida, apliquei pd.get_dummies para gerar\n",
        "### uma coluna numérica (ocean_COASTAL) que vale 1 para distritos costeiros e 0 para os do interior.\n",
        "### Assim, removemos a coluna categórica original (ocean_proximity) e ficamos apenas com atributos numéricos,\n",
        "### permitindo que o modelo interprete corretamente esse fator geográfico sem assumir nenhuma ordem artificial entre categorias.\n",
        "\n",
        "if 'ocean_proximity' in df_fe.columns:\n",
        "    ### Tudo que não é INLAND vira COASTAL\n",
        "    df_fe['ocean_proximity_grp'] = np.where(\n",
        "        df_fe['ocean_proximity'] == 'INLAND',\n",
        "        'INLAND',\n",
        "        'COASTAL'\n",
        "    )\n",
        "\n",
        "    ### Removendo a coluna original\n",
        "    df_fe.drop(columns=['ocean_proximity'], inplace=True)\n",
        "\n",
        "    ### Aplicando One-hot encoding da categoria reduzida (INLAND x COASTAL)\n",
        "    dummies_ocean = pd.get_dummies(\n",
        "        df_fe['ocean_proximity_grp'],\n",
        "        prefix='ocean',\n",
        "        drop_first=True\n",
        "    )\n",
        "\n",
        "    df_fe = pd.concat(\n",
        "        [df_fe.drop(columns=['ocean_proximity_grp']), dummies_ocean],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "df_fe"
      ],
      "metadata": {
        "id": "9MtzSDyqtYUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "As5UcCP-ta-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}